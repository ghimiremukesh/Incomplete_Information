{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4589ff6f",
   "metadata": {},
   "source": [
    "## Code for Non-Revealing Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0981d73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238be156",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f0c6df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to print the payoff table\n",
    "def printMatrix(s):\n",
    "\n",
    "    # Do heading\n",
    "    print(\"     \", end=\"\")\n",
    "    for j in range(len(s[0])):\n",
    "        print(\"%5s \" % j, end=\"\")\n",
    "    print()\n",
    "    print(\"     \", end=\"\")\n",
    "    for j in range(len(s[0])):\n",
    "        print(\"------\", end=\"\")\n",
    "    print()\n",
    "    # Matrix contents\n",
    "    for i in range(len(s)):\n",
    "        print(\"%3s |\" % (i), end=\"\") # Row nums\n",
    "        for j in range(len(s[0])):\n",
    "            if type(s[i][j]) == np.float64:\n",
    "                temp = round(s[i][j], 2)\n",
    "            else:\n",
    "                temp = s[i][j]\n",
    "            print(\"%5s \" % (temp), end=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2b093599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average payoff matrix of two types\n",
    "def get_av_val(val_r, val_l, p):\n",
    "    return p*val_l + (1-p)*val_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bda1fa1",
   "metadata": {},
   "source": [
    "In the non-revealing game, we need to build the value function as: $V(x, t, p) = cav\\;\\;\\max_u \\min_v V(x', t+1, p)$. Previously we just built it as: $V(x, t, p) = \\max_u \\min_v V(x', t+1, p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9427936",
   "metadata": {},
   "source": [
    "### Game Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3e4e2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = 5\n",
    "s = np.linspace(0, num_states-1, num_states)\n",
    "states = np.array(list(itertools.product(s, repeat=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a66c33",
   "metadata": {},
   "source": [
    "### Value Function for any time t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "556ffd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inter_value(timestep, game_dict, states, returnstate=0):\n",
    "    \n",
    "    def get_game_dict(timestep, game_dict, states, valuefun = get_inter_value):\n",
    "        return valuefun(timestep, game_dict, states, returnstate=1)\n",
    "    \n",
    "    # get game dict for t-1 timestep to calculate value at t\n",
    "    if timestep > 1 and returnstate ==0:\n",
    "        temp_game = copy.deepcopy(game_dict)\n",
    "        for i in range(1, timestep):\n",
    "            average, _ = get_game_dict(i, temp_game, states)\n",
    "            temp_game = dict(zip(states.flatten(), average.flatten()))\n",
    "\n",
    "        game_dict = copy.deepcopy(temp_game)\n",
    "#         printMatrix(average)\n",
    "    \n",
    "    \n",
    "    temp = np.full(states.shape, np.nan)\n",
    "    action = np.full(states.shape, '%', dtype='U25')\n",
    "    p1_amap = {'0': 'l', '1': 'L', '2': 'r', '3': 'R'}\n",
    "    p2_amap = {'0': 'l', '1': 'r'}\n",
    "        \n",
    "        \n",
    "    # first row value # min max\n",
    "    for i in range(timestep):\n",
    "        for j in range(timestep, num_states-timestep):\n",
    "#             temp[i, j] = game_dict[states[i, j]]\n",
    "            payoff = np.zeros((4, 2)) \n",
    "            if i - 1 < 0:\n",
    "                new_L = i\n",
    "                new_l = i\n",
    "            elif i - 2 < 0:\n",
    "                new_L = i - 1\n",
    "                new_l = i - 1\n",
    "            else:\n",
    "                new_l = i - 1\n",
    "                new_L = i - 2\n",
    "            \n",
    "            payoff[0, 0] = game_dict[states[new_l, j-1]] # left left\n",
    "            payoff[0, 1] = game_dict[states[new_l, j+1]] # left right\n",
    "            payoff[1, 0] = game_dict[states[new_L, j-1]] # Left left\n",
    "            payoff[1, 1] = game_dict[states[new_L, j+1]] # Left right\n",
    "            payoff[2, 0] = game_dict[states[i+1, j-1]] # right left\n",
    "            payoff[2, 1] = game_dict[states[i+1, j+1]] # right right\n",
    "            payoff[3, 0] = game_dict[states[i+2, j-1]] # Right left\n",
    "            payoff[3, 1] = game_dict[states[i+2, j+1]] # Right right\n",
    "        \n",
    "            # find maximin\n",
    "            temp[i, j] = np.max(np.min(payoff, 1))\n",
    "            action_idx = np.where(np.min(payoff, 1) == temp[i, j])[0] # check for same values\n",
    "            if len(action_idx) == 1:\n",
    "                action[i, j] = p1_amap[str(action_idx[0])] \n",
    "            elif len(action_idx) == 4:\n",
    "                action[i, j] = 'A'\n",
    "            else:\n",
    "                ac = ''\n",
    "                for a in action_idx:\n",
    "                    ac += p1_amap[str(a)]\n",
    "                action[i, j] = ac\n",
    "    \n",
    "#     printMatrix(temp)\n",
    "    # last row value\n",
    "    for i in range(num_states - timestep, num_states):\n",
    "        for j in range(timestep, num_states-timestep):\n",
    "#             temp[i, j] = game_dict[states[i, j]]\n",
    "            payoff = np.zeros((4, 2)) \n",
    "            if i + 1 > num_states - 1:\n",
    "                new_R = i\n",
    "                new_r = i\n",
    "            elif i + 2 > num_states - 1:\n",
    "                new_r = i + 1 \n",
    "                new_R = i + 1\n",
    "            else:\n",
    "                new_r = i + 1\n",
    "                new_R = i + 2\n",
    "            \n",
    "            payoff[0, 0] = game_dict[states[i-1, j-1]] # left left\n",
    "            payoff[0, 1] = game_dict[states[i-1, j+1]] # left right\n",
    "            payoff[1, 0] = game_dict[states[i-2, j-1]] # Left left\n",
    "            payoff[1, 1] = game_dict[states[i-2, j+1]] # Left right\n",
    "            payoff[2, 0] = game_dict[states[new_r, j-1]] # right left\n",
    "            payoff[2, 1] = game_dict[states[new_r, j+1]] # right right\n",
    "            payoff[3, 0] = game_dict[states[new_R, j-1]] # Right left\n",
    "            payoff[3, 1] = game_dict[states[new_R, j+1]] # Right right\n",
    "        \n",
    "            # find maximin\n",
    "            temp[i, j] = np.max(np.min(payoff, 1))\n",
    "            action_idx = np.where(np.min(payoff, 1) == temp[i, j])[0] # check for same values\n",
    "            if len(action_idx) == 1:\n",
    "                action[i, j] = p1_amap[str(action_idx[0])] \n",
    "            elif len(action_idx) == 4:\n",
    "                action[i, j] = 'A'\n",
    "            else:\n",
    "                ac = ''\n",
    "                for a in action_idx:\n",
    "                    ac += p1_amap[str(a)]\n",
    "                action[i, j] = ac\n",
    "\n",
    "        \n",
    "    for i in range(timestep, num_states - timestep): # row\n",
    "        for j in range(timestep, num_states - timestep): # column\n",
    "            payoff = np.zeros((4, 2)) # payoff matrix for each game\n",
    "            if i - 2 < 0:\n",
    "                new_l = i - 1\n",
    "            else:\n",
    "                new_l = i - 2\n",
    "            if i + 2 > num_states - 1: #14:\n",
    "                new_r = i + 1\n",
    "            else:\n",
    "                new_r = i + 2\n",
    "                \n",
    "            payoff[0, 0] = game_dict[states[i-1, j-1]] # left left\n",
    "            payoff[0, 1] = game_dict[states[i-1, j+1]] # left right\n",
    "            payoff[1, 0] = game_dict[states[new_l, j-1]] # Left left\n",
    "            payoff[1, 1] = game_dict[states[new_l, j+1]] # Left right\n",
    "            payoff[2, 0] = game_dict[states[i+1, j-1]] # right left\n",
    "            payoff[2, 1] = game_dict[states[i+1, j+1]] # right right\n",
    "            payoff[3, 0] = game_dict[states[new_r, j-1]] # Right left\n",
    "            payoff[3, 1] = game_dict[states[new_r, j+1]] # Right right\n",
    "\n",
    "            # find maximin\n",
    "            temp[i, j] = np.max(np.min(payoff, 1))\n",
    "            action_idx = np.where(np.min(payoff, 1) == temp[i, j])[0] # check for same values\n",
    "            if len(action_idx) == 1:\n",
    "                action[i, j] = p1_amap[str(action_idx[0])] \n",
    "            elif len(action_idx) == 4:\n",
    "                action[i, j] = 'A'\n",
    "            else:\n",
    "                ac = ''\n",
    "                for a in action_idx:\n",
    "                    ac += p1_amap[str(a)]\n",
    "                action[i, j] = ac\n",
    "\n",
    "    return temp, action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07fa7f8",
   "metadata": {},
   "source": [
    "### Some Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "37318917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payoff for P1: Type Left\n",
    "val_L_T = np.zeros((len(s), len(s)))\n",
    "for i in range(num_states):\n",
    "    val_L_T[np.triu_indices(num_states, k = i)] = i\n",
    "\n",
    "val_L_T = val_L_T.reshape(num_states, num_states)\n",
    "val_R_T = val_L_T.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5bdeab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_pairs = np.array([[''.join(str(states[i, :])) for i in range(len(states))]])\n",
    "s_pairs = s_pairs.reshape(num_states, num_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "883490f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# set p\n",
    "p = 0\n",
    "timestep = 1\n",
    "\n",
    "average_game = get_av_val(val_R_T, val_L_T, p=p)\n",
    "average_dict = dict(zip(s_pairs.flatten(), average_game.flatten()))\n",
    "cav_v, _, = get_inter_value(1, average_dict, s_pairs)\n",
    "ps = np.linspace(0, 1, 50)\n",
    "cav_test = np.zeros((5, 5, len(ps)))\n",
    "for i in range(len(ps)):\n",
    "    average_game = get_av_val(val_R_T, val_L_T, p=ps[i])\n",
    "    average_dict = dict(zip(s_pairs.flatten(), average_game.flatten()))\n",
    "    temp, _ = get_inter_value(1, average_dict, s_pairs)\n",
    "    cav_test[:, :, i] = temp\n",
    "    \n",
    "for row in range(5):\n",
    "    for col in range(timestep, num_states-timestep):\n",
    "        vals = cav_test[row, col, :]\n",
    "        if len(np.where(vals == np.max(vals))[0]) > 1:\n",
    "            p_min = ps[np.where(vals == np.max(vals))[0][0]]\n",
    "            if row == 2 and col == 2:\n",
    "                print(p_min)\n",
    "            if p > p_min:\n",
    "                cav_v[row, col] = np.max(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "99a238e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0     1     2     3     4 \n",
      "     ------------------------------\n",
      "  0 |  nan   0.0   0.0   0.0   nan \n",
      "  1 |  nan   1.0   0.0   0.0   nan \n",
      "  2 |  nan   2.0   1.0   0.0   nan \n",
      "  3 |  nan   2.0   1.0   0.0   nan \n",
      "  4 |  nan   2.0   1.0   0.0   nan \n"
     ]
    }
   ],
   "source": [
    "printMatrix(cav_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "076dc460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0     1     2     3     4 \n",
      "     ------------------------------\n",
      "  0 |  nan   0.4   0.4   0.8   nan \n",
      "  1 |  nan   0.6   0.4   0.8   nan \n",
      "  2 |  nan   1.2   1.0   0.8   nan \n",
      "  3 |  nan   1.2   0.6   0.4   nan \n",
      "  4 |  nan   1.2   0.6   0.4   nan \n"
     ]
    }
   ],
   "source": [
    "printMatrix(cav_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c6f49281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13d0abc40>]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ps, cav_test[2, 2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "09ed9dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cav_v[2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "7771d2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.5, 1. , 1.5, 2. ],\n",
       "       [0.5, 0. , 0.5, 1. , 1.5],\n",
       "       [1. , 0.5, 0. , 0.5, 1. ],\n",
       "       [1.5, 1. , 0.5, 0. , 0.5],\n",
       "       [2. , 1.5, 1. , 0.5, 0. ]])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_av_val(val_R_T, val_L_T, p = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f672e8d",
   "metadata": {},
   "source": [
    "### Calculate Cav of V -- For 2 Time steps (state_dim = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "4a84580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cav_v(timestep, game_dict, states, p, returnstate=0):\n",
    "    \n",
    "    def get_game_dict(timestep, game_dict, states, p, valuefun = get_cav_v):\n",
    "        return valuefun(timestep, game_dict, states, p, returnstate=1)\n",
    "    \n",
    "    if timestep == 1:\n",
    "        cav_v, _, = get_inter_value(1, game_dict, states)\n",
    "        ps = np.linspace(0, 1, 50)\n",
    "        cav_test = np.zeros((5, 5, len(ps)))\n",
    "        ps = np.linspace(0, 1, 50)\n",
    "        cav_test = np.zeros((5, 5, len(ps)))\n",
    "        for i in range(len(ps)):\n",
    "            average_game = get_av_val(val_R_T, val_L_T, p=ps[i])\n",
    "            average_dict = dict(zip(s_pairs.flatten(), average_game.flatten()))\n",
    "            temp, _ = get_inter_value(1, average_dict, s_pairs)\n",
    "            cav_test[:, :, i] = temp\n",
    "\n",
    "        for row in range(5):\n",
    "            for col in range(timestep, num_states-timestep):\n",
    "                vals = cav_test[row, col, :]\n",
    "                if len(np.where(vals == np.max(vals))[0]) > 1:\n",
    "                    p_min = ps[np.where(vals == np.max(vals))[0][0]]\n",
    "                    p_max = ps[np.where(vals == np.max(vals))[0][-1]]\n",
    "                    if p > p_min and p < p_max:\n",
    "                        cav_v[row, col] = np.max(vals)\n",
    "#         print(p)\n",
    "#         if p > 0.37:\n",
    "#             printMatrix(cav_v)\n",
    "#             input()\n",
    "    \n",
    "    if timestep > 1 and returnstate==0:\n",
    "        ps = np.linspace(0, 1, 50)\n",
    "        cav_v, _, = get_inter_value(timestep, game_dict, states)\n",
    "        for i in range(1, timestep):\n",
    "            cavs = np.zeros((num_states, num_states, len(ps)))\n",
    "            for j in range(len(ps)):\n",
    "                av_game = get_av_val(val_R_T, val_L_T, p=ps[j])\n",
    "                av_dict = dict(zip(states.flatten(), av_game.flatten()))\n",
    "                cavs[:, :, j] = get_game_dict(i, av_dict, states, p=ps[j])\n",
    "            \n",
    "            for row in range(num_states):\n",
    "                for col in range(i, num_states-i):\n",
    "                    vals = cavs[row, col, :]\n",
    "#                     if row == 0 and col == 1:\n",
    "#                         print(np.where(vals == np.max(vals)))\n",
    "                    if len(np.where(vals == np.max(vals))[0]) > 1:\n",
    "                        p_min = ps[np.where(vals == np.max(vals))[0][0]]\n",
    "                        p_max = ps[np.where(vals == np.max(vals))[0][-1]]\n",
    "#                         print(p_max)\n",
    "                        if p > p_min and p < p_max:\n",
    "                            cav_v[row, col] = np.max(vals)\n",
    "    return cav_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "64d388db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0     1     2     3     4 \n",
      "     ------------------------------\n",
      "  0 |  nan   0.1   0.1   0.2   nan \n",
      "  1 |  nan   0.9   0.1   0.2   nan \n",
      "  2 |  nan   1.8   1.0   0.2   nan \n",
      "  3 |  nan   1.8   0.9   0.1   nan \n",
      "  4 |  nan   1.8   0.9   0.1   nan \n"
     ]
    }
   ],
   "source": [
    "num_states = 5\n",
    "average_game = get_av_val(val_R_T, val_L_T, p=0.1)\n",
    "average_dict = dict(zip(s_pairs.flatten(), average_game.flatten()))\n",
    "printMatrix(get_cav_v(1, average_dict, s_pairs, p=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "5aefe171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0     1     2     3     4 \n",
      "     ------------------------------\n",
      "  0 |  nan   0.1   0.1   0.2   nan \n",
      "  1 |  nan   0.9   0.1   0.2   nan \n",
      "  2 |  nan   1.8   1.0   0.2   nan \n",
      "  3 |  nan   1.8   0.9   0.1   nan \n",
      "  4 |  nan   1.8   0.9   0.1   nan \n"
     ]
    }
   ],
   "source": [
    "printMatrix(get_cav_v(1, average_dict, s_pairs, p=0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "4c6f88c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "import random\n",
    "from itertools import product\n",
    "\n",
    "def get_strategy(game_dict, states, p):\n",
    "    '''\n",
    "    @params: lambda_j >= 0\n",
    "             p_j \\in {p_1, 1-p_1}\n",
    "             \n",
    "    @constraints: \\sum lambda_j = 1\n",
    "                 \\sum lambda_j*p_j = p\n",
    "    '''\n",
    "    # first get strategy at initial time-step\n",
    "    # initial state is always (2, 2)\n",
    "    \n",
    "    def optimization(p, V_curr, curr_x, game_dict):\n",
    "    \n",
    "        def constraint(var):\n",
    "            lam_1 = var[0]\n",
    "            lam_2 = 1 - lam_1\n",
    "            p_1 = var[1]\n",
    "            p_2 = var[2]\n",
    "#             p_2 = (p - lam_1*p_1)/(lam_2 + 1e-10)\n",
    "\n",
    "            lam_j = np.array([[lam_1], [lam_2]])\n",
    "            p_j = np.array([[p_1], [p_2]])\n",
    "            \n",
    "#             return p_2 >= 0 and p_2 <= 1\n",
    "#\n",
    "            return abs((np.matmul(lam_j.T, p_j) - p).item()) <= 1e-6\n",
    "\n",
    "        def objective(var):\n",
    "\n",
    "            # here, V_curr is the value at the current state\n",
    "            # V_next is the max min value at the previous state leading to current state\n",
    "            lam_1 = var[0]\n",
    "            lam_2 = 1 - lam_1\n",
    "            p_1 = var[1]\n",
    "            p_2 = var[2]\n",
    "#             p_2 = (p - lam_1*p_1)/(lam_2+1e-10)\n",
    "\n",
    "            lam_j = np.array([[lam_1], [lam_2]])\n",
    "            v_next = np.zeros((2, 1))\n",
    "            if curr_x == [2, 2]:\n",
    "                game_dict_1 = get_av_val(val_R_T, val_L_T, p_1)\n",
    "                game_dict_1 = dict(zip(states.flatten(), game_dict_1.flatten()))\n",
    "                game_dict_2 = get_av_val(val_R_T, val_L_T, p_2)\n",
    "                game_dict_2 = dict(zip(states.flatten(), game_dict_2.flatten()))\n",
    "                v_next_0 = get_cav_v(1, game_dict_1, states, p_1)\n",
    "                v_next_1 = get_cav_v(1, game_dict_2, states, p_2)\n",
    "                \n",
    "                pay_0 = np.zeros((4, 2))\n",
    "                pay_1 = np.zeros((4, 2))\n",
    "                \n",
    "                pay_0[0, 0] = v_next_0[1, 1]\n",
    "                pay_0[0, 1] = v_next_0[1, 3]\n",
    "                pay_0[1, 0] = v_next_0[0, 1]\n",
    "                pay_0[1, 1] = v_next_0[0, 3]\n",
    "                pay_0[2, 0] = v_next_0[3, 1]\n",
    "                pay_0[2, 1] = v_next_0[3, 3]\n",
    "                pay_0[3, 0] = v_next_0[4, 1]\n",
    "                pay_0[3, 1] = v_next_0[4, 3]\n",
    "                \n",
    "                pay_1[0, 0] = v_next_1[1, 1]\n",
    "                pay_1[0, 1] = v_next_1[1, 3]\n",
    "                pay_1[1, 0] = v_next_1[0, 1]\n",
    "                pay_1[1, 1] = v_next_1[0, 3]\n",
    "                pay_1[2, 0] = v_next_1[3, 1]\n",
    "                pay_1[2, 1] = v_next_1[3, 3]\n",
    "                pay_1[3, 0] = v_next_1[4, 1]\n",
    "                pay_1[3, 1] = v_next_1[4, 3]\n",
    "                \n",
    "                # do min max on v_next\n",
    "                v_next[0] = np.max(np.min(pay_0, 1))\n",
    "                v_next[1] = np.max(np.min(pay_1, 1))\n",
    "                \n",
    "            else: # that is, some other state in the second time-step\n",
    "                \n",
    "                i = curr_x[0]\n",
    "                j = curr_x[1]\n",
    "                \n",
    "                v_next_0 = get_av_val(val_R_T, val_L_T, p_1)\n",
    "                v_next_1 = get_av_val(val_R_T, val_L_T, p_2)\n",
    "                \n",
    "                pay_0 = np.zeros((4, 2))\n",
    "                pay_1 = np.zeros((4, 2))\n",
    "                \n",
    "                if i - 1 < 0:\n",
    "                    new_L = i\n",
    "                    new_l = i\n",
    "                elif i - 2 < 0:\n",
    "                    new_L = i - 1\n",
    "                    new_l = i - 1\n",
    "                else:\n",
    "                    new_l = i - 1\n",
    "                    new_L = i - 2\n",
    "                    \n",
    "                if i + 1 > num_states - 1:\n",
    "                    new_R = i\n",
    "                    new_r = i\n",
    "                elif i + 2 > num_states - 1:\n",
    "                    new_r = i + 1 \n",
    "                    new_R = i + 1\n",
    "                else:\n",
    "                    new_r = i + 1\n",
    "                    new_R = i + 2\n",
    "\n",
    "                pay_0[0, 0] = v_next_0[new_l, j-1] # left left\n",
    "                pay_0[0, 1] = v_next_0[new_l, j+1] # left right\n",
    "                pay_0[1, 0] = v_next_0[new_L, j-1] # Left left\n",
    "                pay_0[1, 1] = v_next_0[new_L, j+1] # Left right\n",
    "                pay_0[2, 0] = v_next_0[new_r, j-1] # right left\n",
    "                pay_0[2, 1] = v_next_0[new_r, j+1] # right right\n",
    "                pay_0[3, 0] = v_next_0[new_R, j-1] # Right left\n",
    "                pay_0[3, 1] = v_next_0[new_R, j+1] # Right right\n",
    "                \n",
    "                pay_1[0, 0] = v_next_1[new_l, j-1] # left left\n",
    "                pay_1[0, 1] = v_next_1[new_l, j+1] # left right\n",
    "                pay_1[1, 0] = v_next_1[new_L, j-1] # Left left\n",
    "                pay_1[1, 1] = v_next_1[new_L, j+1] # Left right\n",
    "                pay_1[2, 0] = v_next_1[new_r, j-1] # right left\n",
    "                pay_1[2, 1] = v_next_1[new_r, j+1] # right right\n",
    "                pay_1[3, 0] = v_next_1[new_R, j-1] # Right left\n",
    "                pay_1[3, 1] = v_next_1[new_R, j+1] # Right right\n",
    "                \n",
    "                # do min max on v_next\n",
    "                v_next[0] = np.max(np.min(pay_0, 1))\n",
    "                v_next[1] = np.max(np.min(pay_1, 1))\n",
    "                    \n",
    "            \n",
    "            return abs((V_curr -  np.matmul(lam_j.T, v_next)).item())\n",
    "    \n",
    "        \n",
    "        cons = ({'type': 'eq', 'fun': constraint})\n",
    "        bnds = ((0, 1), (0, 1), (0, 1), (p, p))\n",
    "#         x0 = [0, 0, 0, p]\n",
    "        \n",
    "        # cannot use scipy optimization\n",
    "#         res = minimize(objective, x0, bounds = bnds, constraints = cons, options={'disp': True})\n",
    "#         print(objective(x0))\n",
    "\n",
    "        lam = np.linspace(0, 1, 1000)\n",
    "#         p_1 = np.arange(0, 1, 0.25)\n",
    "#         p_2 = np.arange(0, 1, 0.25)\n",
    "        \n",
    "        grid = product(lam, repeat=3)\n",
    "        reduced = filter(constraint, grid)\n",
    "        res = min(reduced, key=objective)\n",
    "#         res = min(grid, key=objective)\n",
    "\n",
    "        print(objective(res))\n",
    "        \n",
    "        \n",
    "        return res\n",
    "       \n",
    "    print(f'Current position is center (2, 2) and the belief is {p}\\n')\n",
    "    p_t = p\n",
    "    a_map = {'0': 'l', '1': 'L', '2': 'r', '3': 'R'}\n",
    "    # first get strategy for initial state (2, 2)\n",
    "    start_x = [2, 2]\n",
    "    V_curr = get_cav_v(2, game_dict, states, p_t)[2, 2]\n",
    "    \n",
    "    lam_j, p_1, p_2 = optimization(p_t, V_curr, start_x, game_dict)\n",
    "#     lam_j, p_1 = optimization(p_t, V_curr, start_x, game_dict)\n",
    "#     p_2 = (p_t - lam_j*p_1)/(1 - lam_j + 1e-10)\n",
    "    print(f'lamda_1 = {lam_j:.2f}, p_1 = {p_1:.2f},  p_2 = {p_2:.2f}\\n')\n",
    "#     input()\n",
    "    \n",
    "    \n",
    "    # action for lam_1 \n",
    "    game_dict_1 = get_av_val(val_R_T, val_L_T, p_1)\n",
    "    game_dict_1 = dict(zip(s_pairs.flatten(), game_dict_1.flatten()))\n",
    "    game_dict_2 = get_av_val(val_R_T, val_L_T, p_2)\n",
    "    game_dict_2 = dict(zip(s_pairs.flatten(), game_dict_2.flatten()))\n",
    "\n",
    "    v_next_0 = get_cav_v(1, game_dict_1, states, p_1)\n",
    "    v_next_1 = get_cav_v(1, game_dict_2, states, p_2)\n",
    "    \n",
    "    pay_0 = np.zeros((4, 2))\n",
    "    pay_1 = np.zeros((4, 2))\n",
    "\n",
    "    pay_0[0, 0] = v_next_0[1, 1]\n",
    "    pay_0[0, 1] = v_next_0[1, 3]\n",
    "    pay_0[1, 0] = v_next_0[0, 1]\n",
    "    pay_0[1, 1] = v_next_0[0, 3]\n",
    "    pay_0[2, 0] = v_next_0[3, 1]\n",
    "    pay_0[2, 1] = v_next_0[3, 3]\n",
    "    pay_0[3, 0] = v_next_0[4, 1]\n",
    "    pay_0[3, 1] = v_next_0[4, 3]\n",
    "    \n",
    "    v_0 = np.max(np.min(pay_0, 1))\n",
    "    a_0 = None\n",
    "    a_0_idx = np.where(np.min(pay_0, 1) == v_0)[0] # check for same values\n",
    "    if len(a_0_idx) == 1:\n",
    "        a_0 = a_map[str(a_0_idx[0])]\n",
    "    elif len(a_0_idx) == 4:\n",
    "        a_0 = 'A'\n",
    "    else:\n",
    "        ac = ''\n",
    "        for a in a_0_idx:\n",
    "            ac += a_map[str(a)]\n",
    "        a_0 = ac\n",
    "\n",
    "    pay_1[0, 0] = v_next_1[1, 1]\n",
    "    pay_1[0, 1] = v_next_1[1, 3]\n",
    "    pay_1[1, 0] = v_next_1[0, 1]\n",
    "    pay_1[1, 1] = v_next_1[0, 3]\n",
    "    pay_1[2, 0] = v_next_1[3, 1]\n",
    "    pay_1[2, 1] = v_next_1[3, 3]\n",
    "    pay_1[3, 0] = v_next_1[4, 1]\n",
    "    pay_1[3, 1] = v_next_1[4, 3]\n",
    "    \n",
    "    v_1 = np.max(np.min(pay_1, 1))\n",
    "    a_1 = None\n",
    "    a_1_idx = np.where(np.min(pay_1, 1) == v_1)[0] # check for same values\n",
    "    if len(a_1_idx) == 1:\n",
    "        a_1 = a_map[str(a_1_idx[0])]\n",
    "    elif len(a_1_idx) == 4:\n",
    "        a_1 = 'A'\n",
    "    else:\n",
    "        ac = ''\n",
    "        for a in a_1_idx:\n",
    "            ac += a_map[str(a)]\n",
    "        a_1 = ac\n",
    "        \n",
    "    # calculate probability of each action\n",
    "    if p1_type == 0:\n",
    "        p_i = 1 - p_t\n",
    "        p_1j = 1 - p_1\n",
    "        p_2j = 1 - p_2\n",
    "    else:\n",
    "        p_i = p_t \n",
    "        p_1j = p_1\n",
    "        p_2j = p_2\n",
    "    \n",
    "    a0_p = (lam_j * p_1j)/p_i\n",
    "    a1_p = ((1-lam_j) * p_2j)/p_i\n",
    "    \n",
    "    print('At initial time, P1 has the following options: \\n')\n",
    "    print(f'P1 takes action {a_0} with probability {a0_p:.2f} and moves belief to {p_1:.2f}')\n",
    "    print(f'P1 takes action {a_1} with probability {a1_p:.2f} and moves belief to {p_2:.2f}\\n')\n",
    "    \n",
    "    # Now get strategy for second stage:\n",
    "    \n",
    "#     a_0 = np.random.choice(list(a_map.keys()), size=1, p=[0.25, 0.25, 0.25, 0.25])\n",
    "#     print(a_map[a_0.item()])\n",
    "    dist = [a0_p, a1_p]\n",
    "    a_idx = [0, 1]\n",
    "    action_idx = random.choices(a_idx, dist)[0]\n",
    "    if action_idx == 0:\n",
    "        action_1 = a_0\n",
    "        p_t = p_1\n",
    "    else:\n",
    "        action_1 = a_1\n",
    "        p_t = p_2\n",
    "        \n",
    "     # for simulation purpose select p2's action randomly\n",
    "    p2_a = random.choices([1, -1], [0.5, 0.5])[0] # left or right\n",
    "    p2_action = 'l' if p2_a == -1 else 'r'\n",
    "    \n",
    "    \n",
    "    print(f'P1 chooses action: {action_1} and moves the belief to p_t = {p_t:.2f}')\n",
    "    print(f'P2 chooses action: {p2_action} at random\\n')\n",
    "    ##########################################################################################\n",
    "    #################################### NEXT TIME-STEP ######################################\n",
    "    ##########################################################################################\n",
    "    \n",
    "   \n",
    "    \n",
    "    if action_1 == 'l':\n",
    "        step = -1\n",
    "    elif action_1 == 'r':\n",
    "        step = 1\n",
    "    elif action_1 == 'L':\n",
    "        step = -2\n",
    "    elif aciton_1 == 'R':\n",
    "        step = 2\n",
    "    \n",
    "    curr_x = start_x\n",
    "    curr_x = np.array(curr_x) + np.array([step, p2_a])  # get current position\n",
    "    \n",
    "    print(f'The current position is: {curr_x}\\n')\n",
    "    \n",
    "    game = get_av_val(val_R_T, val_L_T, p=p_t)\n",
    "    game_dict = dict(zip(states.flatten(), game.flatten()))\n",
    "    V_curr = get_cav_v(1, game_dict, states, p_t)[curr_x[0], curr_x[1]]\n",
    "    \n",
    "    lam_j, p_1, p_2 = optimization(p_t, V_curr, list(curr_x), game_dict)\n",
    "#     lam_j, p_1 = optimization(p_t, V_curr, list(curr_x), game_dict)\n",
    "#     p_2 = (p_t - lam_j*p_1)/(1 - lam_j + 1e-10)\n",
    "    \n",
    "    print(f'lamda_1 = {lam_j:.2f}, p_1 = {p_1:.2f},  p_2 = {p_2:.2f}\\n')\n",
    "    \n",
    "    \n",
    "    # action for lam_1 \n",
    "    game_dict_1 = get_av_val(val_R_T, val_L_T, p_1)\n",
    "#     game_dict_1 = dict(zip(s_pairs.flatten(), game_dict_1.flatten()))\n",
    "    game_dict_2 = get_av_val(val_R_T, val_L_T, p_2)\n",
    "#     game_dict_2 = dict(zip(s_pairs.flatten(), game_dict_2.flatten()))\n",
    "\n",
    "#     v_next_0 = get_cav_v(1, game_dict_1, states, p_1)\n",
    "#     v_next_1 = get_cav_v(1, game_dict_2, states, p_2)\n",
    "    v_next_0 = game_dict_1\n",
    "    v_next_1 = game_dict_2\n",
    "    \n",
    "    pay_0 = np.zeros((4, 2))\n",
    "    pay_1 = np.zeros((4, 2))\n",
    "    \n",
    "    i = curr_x[0]\n",
    "    j = curr_x[1]\n",
    "    \n",
    "    if i - 1 < 0:\n",
    "        new_L = i\n",
    "        new_l = i\n",
    "    elif i - 2 < 0:\n",
    "        new_L = i - 1\n",
    "        new_l = i - 1\n",
    "    else:\n",
    "        new_l = i - 1\n",
    "        new_L = i - 2\n",
    "\n",
    "    if i + 1 > num_states - 1:\n",
    "        new_R = i\n",
    "        new_r = i\n",
    "    elif i + 2 > num_states - 1:\n",
    "        new_r = i + 1 \n",
    "        new_R = i + 1\n",
    "    else:\n",
    "        new_r = i + 1\n",
    "        new_R = i + 2\n",
    "\n",
    "#     print(new_l, new_L, new_r, new_R)\n",
    "    \n",
    "    pay_0[0, 0] = v_next_0[new_l, j-1] # left left\n",
    "    pay_0[0, 1] = v_next_0[new_l, j+1] # left right\n",
    "    pay_0[1, 0] = v_next_0[new_L, j-1] # Left left\n",
    "    pay_0[1, 1] = v_next_0[new_L, j+1] # Left right\n",
    "    pay_0[2, 0] = v_next_0[new_r, j-1] # right left\n",
    "    pay_0[2, 1] = v_next_0[new_r, j+1] # right right\n",
    "    pay_0[3, 0] = v_next_0[new_R, j-1] # Right left\n",
    "    pay_0[3, 1] = v_next_0[new_R, j+1] # Right right\n",
    "\n",
    "    v_0 = np.max(np.min(pay_0, 1))\n",
    "    a_0 = None\n",
    "#     printMatrix(pay_0)\n",
    "    a_0_idx = np.where(np.min(pay_0, 1) == v_0)[0] # check for same values\n",
    "#     print(a_0_idx)\n",
    "    if len(a_0_idx) == 1:\n",
    "        a_0 = a_map[str(a_0_idx[0])]\n",
    "    elif len(a_0_idx) == 4:\n",
    "        a_0 = 'A'\n",
    "    else:\n",
    "        ac = ''\n",
    "        for a in a_0_idx:\n",
    "            ac += a_map[str(a)]\n",
    "        a_0 = ac\n",
    "\n",
    "    pay_1[0, 0] = v_next_1[new_l, j-1] # left left\n",
    "    pay_1[0, 1] = v_next_1[new_l, j+1] # left right\n",
    "    pay_1[1, 0] = v_next_1[new_L, j-1] # Left left\n",
    "    pay_1[1, 1] = v_next_1[new_L, j+1] # Left right\n",
    "    pay_1[2, 0] = v_next_1[new_r, j-1] # right left\n",
    "    pay_1[2, 1] = v_next_1[new_r, j+1] # right right\n",
    "    pay_1[3, 0] = v_next_1[new_R, j-1] # Right left\n",
    "    pay_1[3, 1] = v_next_1[new_R, j+1] # Right right\n",
    "\n",
    "    v_1 = np.max(np.min(pay_1, 1))\n",
    "    a_1 = None\n",
    "    a_1_idx = np.where(np.min(pay_1, 1) == v_1)[0] # check for same values\n",
    "    \n",
    "    if len(a_1_idx) == 1:\n",
    "        a_1 = a_map[str(a_1_idx[0])]\n",
    "    elif len(a_1_idx) == 4:\n",
    "        a_1 = 'A'\n",
    "    else:\n",
    "        ac = ''\n",
    "        for a in a_1_idx:\n",
    "            ac += a_map[str(a)]\n",
    "        a_1 = ac\n",
    "        \n",
    "    # calculate probability of each action\n",
    "    if p1_type == 0:\n",
    "        p_i = 1 - p_t\n",
    "        p_1j = 1 - p_1\n",
    "        p_2j = 1 - p_2\n",
    "    else:\n",
    "        p_i = p_t \n",
    "        p_1j = p_1\n",
    "        p_2j = p_2\n",
    "    \n",
    "    a0_p = (lam_j * p_1j)/p_i\n",
    "    a1_p = ((1-lam_j) * p_2j)/p_i\n",
    "    \n",
    "    print('At the second time-step, P1 has the following options: \\n')\n",
    "    print(f'P1 takes action {a_0} with probability {a0_p:.2f} and moves belief to {p_1:.2f}')\n",
    "    print(f'P1 takes action {a_1} with probability {a1_p:.2f} and moves belief to {p_2:.2f}\\n')\n",
    "    \n",
    "    # Now get strategy for second stage:\n",
    "    # assume we know action at t0 is A (anything)\n",
    "    \n",
    "#     a_0 = np.random.choice(list(a_map.keys()), size=1, p=[0.25, 0.25, 0.25, 0.25])\n",
    "#     print(a_map[a_0.item()])\n",
    "    dist = [a0_p, a1_p]\n",
    "    a_idx = [0, 1]\n",
    "    action_idx = random.choices(a_idx, dist)[0]\n",
    "    if action_idx == 0:\n",
    "        action_1 = a_0\n",
    "        p_t = p_1\n",
    "    else:\n",
    "        action_1 = a_1\n",
    "        p_t = p_2\n",
    "        \n",
    "    \n",
    "    return (a_0, lam_j, p_1), (a_1, 1-lam_j, p_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "43110ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = 5\n",
    "# curr_x = [2, 2]\n",
    "p = 0.5\n",
    "p1_type = 1 # 0 for right, 1 for left\n",
    "average_game = get_av_val(val_R_T, val_L_T, p=p)\n",
    "average_dict = dict(zip(s_pairs.flatten(), average_game.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "1e21b3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current position is center (2, 2) and the belief is 0.5\n",
      "\n",
      "0.34303572842111374\n",
      "lamda_1 = 0.52, p_1 = 0.35,  p_2 = 0.66\n",
      "\n",
      "At initial time, P1 has the following options: \n",
      "\n",
      "P1 takes action l with probability 0.36 and moves belief to 0.35\n",
      "P1 takes action r with probability 0.64 and moves belief to 0.66\n",
      "\n",
      "P1 chooses action: l and moves the belief to p_t = 0.35\n",
      "P2 chooses action: r at random\n",
      "\n",
      "The current position is: [1 3]\n",
      "\n",
      "0.0\n",
      "lamda_1 = 0.00, p_1 = 0.00,  p_2 = 0.35\n",
      "\n",
      "At the second time-step, P1 has the following options: \n",
      "\n",
      "P1 takes action A with probability 0.00 and moves belief to 0.00\n",
      "P1 takes action lL with probability 1.00 and moves belief to 0.35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l_1, l_2 = get_strategy(average_dict, s_pairs, p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "c571928d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2., 3., 4.],\n",
       "       [0., 0., 1., 2., 3.],\n",
       "       [0., 0., 0., 1., 2.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_av_val(val_R_T, val_L_T, p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689d6ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
