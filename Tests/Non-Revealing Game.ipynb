{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Non-Revealing Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to print the payoff table\n",
    "def printMatrix(s):\n",
    "\n",
    "    # Do heading\n",
    "    print(\"     \", end=\"\")\n",
    "    for j in range(len(s[0])):\n",
    "        print(\"%5s \" % j, end=\"\")\n",
    "    print()\n",
    "    print(\"     \", end=\"\")\n",
    "    for j in range(len(s[0])):\n",
    "        print(\"------\", end=\"\")\n",
    "    print()\n",
    "    # Matrix contents\n",
    "    for i in range(len(s)):\n",
    "        print(\"%3s |\" % (i), end=\"\") # Row nums\n",
    "        for j in range(len(s[0])):\n",
    "            if type(s[i][j]) == np.float64:\n",
    "                temp = round(s[i][j], 2)\n",
    "            else:\n",
    "                temp = s[i][j]\n",
    "            print(\"%5s \" % (temp), end=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average payoff matrix of two types\n",
    "def get_av_val(val_r, val_l, p):\n",
    "    return p*val_l + (1-p)*val_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the non-revealing game, we need to build the value function as: $V(x, t, p) = cav\\;\\;\\min_u \\max_v V(x', t+1, p)$. Previously we just built it as: $V(x, t, p) = \\min_u \\max_v V(x', t+1, p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = 5\n",
    "s = np.linspace(0, num_states-1, num_states)\n",
    "states = np.array(list(itertools.product(s, repeat=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Function for any time t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inter_value(timestep, game_dict, states, returnstate=0):\n",
    "    \n",
    "    def get_game_dict(timestep, game_dict, states, valuefun = get_inter_value):\n",
    "        return valuefun(timestep, game_dict, states, returnstate=1)\n",
    "    \n",
    "    # get game dict for t-1 timestep to calculate value at t\n",
    "    if timestep > 1 and returnstate ==0:\n",
    "        temp_game = copy.deepcopy(game_dict)\n",
    "        for i in range(1, timestep):\n",
    "            average, _ = get_game_dict(i, temp_game, states)\n",
    "            temp_game = dict(zip(states.flatten(), average.flatten()))\n",
    "\n",
    "        game_dict = copy.deepcopy(temp_game)\n",
    "#         printMatrix(average)\n",
    "    \n",
    "    \n",
    "    temp = np.full(states.shape, np.nan)\n",
    "    action = np.full(states.shape, '%', dtype='U25')\n",
    "    p1_amap = {'0': 'l', '1': 'L', '2': 'r', '3': 'R'}\n",
    "    p2_amap = {'0': 'l', '1': 'r'}\n",
    "        \n",
    "        \n",
    "    # first row value # min max\n",
    "    for i in range(timestep):\n",
    "        for j in range(timestep, num_states-timestep):\n",
    "#             temp[i, j] = game_dict[states[i, j]]\n",
    "            payoff = np.zeros((4, 2)) \n",
    "            if i - 1 < 0:\n",
    "                new_L = i\n",
    "                new_l = i\n",
    "            elif i - 2 < 0:\n",
    "                new_L = i - 1\n",
    "                new_l = i - 1\n",
    "            else:\n",
    "                new_l = i - 1\n",
    "                new_L = i - 2\n",
    "            \n",
    "            payoff[0, 0] = game_dict[states[new_l, j-1]] # left left\n",
    "            payoff[0, 1] = game_dict[states[new_l, j+1]] # left right\n",
    "            payoff[1, 0] = game_dict[states[new_L, j-1]] # Left left\n",
    "            payoff[1, 1] = game_dict[states[new_L, j+1]] # Left right\n",
    "            payoff[2, 0] = game_dict[states[i+1, j-1]] # right left\n",
    "            payoff[2, 1] = game_dict[states[i+1, j+1]] # right right\n",
    "            payoff[3, 0] = game_dict[states[i+2, j-1]] # Right left\n",
    "            payoff[3, 1] = game_dict[states[i+2, j+1]] # Right right\n",
    "        \n",
    "            # find maximin\n",
    "            temp[i, j] = np.max(np.min(payoff, 1))\n",
    "            action_idx = np.where(np.min(payoff, 1) == temp[i, j])[0] # check for same values\n",
    "            if len(action_idx) == 1:\n",
    "                action[i, j] = p1_amap[str(action_idx[0])] \n",
    "            elif len(action_idx) == 4:\n",
    "                action[i, j] = 'A'\n",
    "            else:\n",
    "                ac = ''\n",
    "                for a in action_idx:\n",
    "                    ac += p1_amap[str(a)]\n",
    "                action[i, j] = ac\n",
    "    \n",
    "#     printMatrix(temp)\n",
    "    # last row value\n",
    "    for i in range(num_states - timestep, num_states):\n",
    "        for j in range(timestep, num_states-timestep):\n",
    "#             temp[i, j] = game_dict[states[i, j]]\n",
    "            payoff = np.zeros((4, 2)) \n",
    "            if i + 1 > num_states - 1:\n",
    "                new_R = i\n",
    "                new_r = i\n",
    "            elif i + 2 > num_states - 1:\n",
    "                new_r = i + 1 \n",
    "                new_R = i + 1\n",
    "            else:\n",
    "                new_r = i + 1\n",
    "                new_R = i + 2\n",
    "            \n",
    "            payoff[0, 0] = game_dict[states[i-1, j-1]] # left left\n",
    "            payoff[0, 1] = game_dict[states[i-1, j+1]] # left right\n",
    "            payoff[1, 0] = game_dict[states[i-2, j-1]] # Left left\n",
    "            payoff[1, 1] = game_dict[states[i-2, j+1]] # Left right\n",
    "            payoff[2, 0] = game_dict[states[new_r, j-1]] # right left\n",
    "            payoff[2, 1] = game_dict[states[new_r, j+1]] # right right\n",
    "            payoff[3, 0] = game_dict[states[new_R, j-1]] # Right left\n",
    "            payoff[3, 1] = game_dict[states[new_R, j+1]] # Right right\n",
    "        \n",
    "            # find maximin\n",
    "            temp[i, j] = np.max(np.min(payoff, 1))\n",
    "            action_idx = np.where(np.min(payoff, 1) == temp[i, j])[0] # check for same values\n",
    "            if len(action_idx) == 1:\n",
    "                action[i, j] = p1_amap[str(action_idx[0])] \n",
    "            elif len(action_idx) == 4:\n",
    "                action[i, j] = 'A'\n",
    "            else:\n",
    "                ac = ''\n",
    "                for a in action_idx:\n",
    "                    ac += p1_amap[str(a)]\n",
    "                action[i, j] = ac\n",
    "\n",
    "        \n",
    "    for i in range(timestep, num_states - timestep): # row\n",
    "        for j in range(timestep, num_states - timestep): # column\n",
    "            payoff = np.zeros((4, 2)) # payoff matrix for each game\n",
    "            if i - 2 < 0:\n",
    "                new_l = i - 1\n",
    "            else:\n",
    "                new_l = i - 2\n",
    "            if i + 2 > num_states - 1: #14:\n",
    "                new_r = i + 1\n",
    "            else:\n",
    "                new_r = i + 2\n",
    "                \n",
    "            payoff[0, 0] = game_dict[states[i-1, j-1]] # left left\n",
    "            payoff[0, 1] = game_dict[states[i-1, j+1]] # left right\n",
    "            payoff[1, 0] = game_dict[states[new_l, j-1]] # Left left\n",
    "            payoff[1, 1] = game_dict[states[new_l, j+1]] # Left right\n",
    "            payoff[2, 0] = game_dict[states[i+1, j-1]] # right left\n",
    "            payoff[2, 1] = game_dict[states[i+1, j+1]] # right right\n",
    "            payoff[3, 0] = game_dict[states[new_r, j-1]] # Right left\n",
    "            payoff[3, 1] = game_dict[states[new_r, j+1]] # Right right\n",
    "\n",
    "            # find maximin\n",
    "            temp[i, j] = np.max(np.min(payoff, 1))\n",
    "            action_idx = np.where(np.min(payoff, 1) == temp[i, j])[0] # check for same values\n",
    "            if len(action_idx) == 1:\n",
    "                action[i, j] = p1_amap[str(action_idx[0])] \n",
    "            elif len(action_idx) == 4:\n",
    "                action[i, j] = 'A'\n",
    "            else:\n",
    "                ac = ''\n",
    "                for a in action_idx:\n",
    "                    ac += p1_amap[str(a)]\n",
    "                action[i, j] = ac\n",
    "\n",
    "    return temp, action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# payoff for P1: Type Left\n",
    "val_L_T = np.zeros((len(s), len(s)))\n",
    "for i in range(num_states):\n",
    "    val_L_T[np.triu_indices(num_states, k = i)] = i\n",
    "\n",
    "val_L_T = val_L_T.reshape(num_states, num_states)\n",
    "val_R_T = val_L_T.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_pairs = np.array([[''.join(str(states[i, :])) for i in range(len(states))]])\n",
    "s_pairs = s_pairs.reshape(num_states, num_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# set p\n",
    "p = 0.9\n",
    "timestep = 1\n",
    "\n",
    "average_game = get_av_val(val_R_T, val_L_T, p=p)\n",
    "average_dict = dict(zip(s_pairs.flatten(), average_game.flatten()))\n",
    "cav_v, _, = get_inter_value(1, average_dict, s_pairs)\n",
    "ps = np.linspace(0, 1, 50)\n",
    "cav_test = np.zeros((5, 5, len(ps)))\n",
    "for i in range(len(ps)):\n",
    "    average_game = get_av_val(val_R_T, val_L_T, p=ps[i])\n",
    "    average_dict = dict(zip(s_pairs.flatten(), average_game.flatten()))\n",
    "    temp, _ = get_inter_value(1, average_dict, s_pairs)\n",
    "    cav_test[:, :, i] = temp\n",
    "    \n",
    "for row in range(5):\n",
    "    for col in range(timestep, num_states-timestep):\n",
    "        vals = cav_test[row, col, :]\n",
    "        if len(np.where(vals == np.max(vals))[0]) > 1:\n",
    "            p_min = ps[np.where(vals == np.max(vals))[0][0]]\n",
    "            if row == 2 and col == 2:\n",
    "                print(p_min)\n",
    "            if p > p_min:\n",
    "                cav_v[row, col] = np.max(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0     1     2     3     4 \n",
      "     ------------------------------\n",
      "  0 |  nan  0.49   0.9   1.8   nan \n",
      "  1 |  nan   0.1   0.9   1.8   nan \n",
      "  2 |  nan   0.2   1.0   1.8   nan \n",
      "  3 |  nan   0.2   0.1   0.9   nan \n",
      "  4 |  nan   0.2   0.1  0.49   nan \n"
     ]
    }
   ],
   "source": [
    "printMatrix(cav_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0     1     2     3     4 \n",
      "     ------------------------------\n",
      "  0 |  nan   0.4   0.4   0.8   nan \n",
      "  1 |  nan   0.6   0.4   0.8   nan \n",
      "  2 |  nan   1.2   1.0   0.8   nan \n",
      "  3 |  nan   1.2   0.6   0.4   nan \n",
      "  4 |  nan   1.2   0.6   0.4   nan \n"
     ]
    }
   ],
   "source": [
    "printMatrix(cav_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe971760438>]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3hUddr/8fedRgghoYUaICCdhBQQcbG3BQsoICXxt+Vx190lgKKui11ZFBuiQFhXfba4D6GIrqKiqIi9YEgh1BB6aAklISGEtO/vj8R98sRghjAz38zM/bquXNeUkzmfk/LJ5J4z54gxBqWUUp7Pz3YApZRSzqGFrpRSXkILXSmlvIQWulJKeQktdKWU8hIBtlbcoUMHExUVZWv1SinlkTZs2HDUGBPR0H3WCj0qKoq0tDRbq1dKKY8kInvPdp+OXJRSyktooSullJfQQldKKS+hha6UUl5CC10ppbxEo4UuIn8TkXwR2XSW+0VEFohIrohsFJEE58dUSinVGEeeof8DGPUT948G+tZ+3AH85fxjKaWUOleNFrox5nPg+E8sMhZ4zdT4FmgjIl2cFbC+nQUlPPX+NvSwv0opT1NdbZjz7hb2Hy91yeM7Y4beDdhf53pe7W0/IiJ3iEiaiKQVFBQ0aWXrtuXz0mc7+efXe5r0+UopZcviT3N59cvdfJl71CWP74xClwZua/DpszHmZWPMMGPMsIiIBt+52qj/GtmLqwd05InVW8naX9ikx1BKKXf7Zucxnv8ohzGxXZl8YXeXrMMZhZ4H1E0XCRx0wuM2yM9PmDcxlo6tg0lOTaeotMJVq1JKKacoKD7DjGUZRLVvxZPjYhBp6Hnw+XNGoa8CflG7t8sIoMgYc8gJj3tWbUKCWJgYz+GiMu5dmaXzdKVUs1VVbbhreQYnT1eQkpRAaAvXHULLkd0WlwLfAP1FJE9EbheR34vI72sXWQ3sAnKBV4CpLktbR0KPtswaPYCPthzhv7/c7Y5VKqXUOVv4yQ6+yj3G7LGDGdglzKXravRPhTFmSiP3GyDZaYnOwe2X9GL97uM89f42Enq2JaFHWxsxlFKqQV/lHuXFtTsYl9CNicNcMzevy6PfKSoiPHtrLF3aBDM9NYPC0nLbkZRSCoD8k2XcuSyDPhGhzLk52mVz87o8utABwlsGkpKYQEHxGe5ZkUV1tc7TlVJ2VVZVM2NZBqfOVLE4KYGQIPecesLjCx1gSGQbHrxhIGu35fPKF7tsx1FK+bgX1+7g213HmXNzNH07tXbber2i0AF+cXFPbojpwjNrtpO256fe2KqUUq7zeU4Bi9blMnFYJOOHRrp13V5T6CLC3PExRLZtybTUDI6VnLEdSSnlYw4XlXHX8kz6dWzN42Oi3b5+ryl0gLDgmnn68dJyZuo8XSnlRpVV1cxYmkFZRRUpSQm0DPJ3ewavKnSA6G7hPHLjID7PKeAvn+20HUcp5SPmfZTD+j3HmTsuhj4dQ61k8LpCB0i6qAc3xXZl3ofb+XbXMdtxlFJebt22fP7y6U6mDO/B2LgGj03oFl5Z6CLC3HExRLVvxYylGRQU6zxdKeUaBwtPM3NFJgO7hPHoTYOsZvHKQgcIbRFASlICRacrmLk8kyqdpyulnKyiqprpSzOorDIsTkogOND9c/O6vLbQAQZ2CePxMYP5Mvcoiz7JtR1HKeVlnl2znQ17T/DU+Bh6dWhlO453FzrApAu7c0t8N15Ym8PXLjqovFLK93y05Qgvf76L/zeiJzcO6Wo7DuADhS4izLk5mt4dWjFjWSb5xWW2IymlPNz+46XcsyKT6G5hPHjDQNtx/sPrCx2gVYsA/nLbUErOVHDnUp2nK6WarryymmlLMzAGUhLtz83r8olCB+jXqTVzbo7hm13HePHjHNtxlFIeau77Nae/fGbCEHq2tz83r8tnCh1gwtBIbh0aycJ1uXye07STVCulfNcHmw7x96/28KufRTE6povtOD/iU4UOMHtsNP06tuau5ZkcLtJ5ulLKMfuOlfLHlRuJjQzngeubz9y8Lp8r9JZB/qQkJVBWUcWMpRlUVlXbjqSUaubOVFaRnJqOAIsSEwgKaJ7V2TxTuVifjqE8eUsM6/ccZ95HOk9XSv20J97bSvaBIp67NZbu7UJsxzkrnyx0gJvjuzFleHf+8ulO1m3Ltx1HKdVMvbvxIK99s5ffXNKL6wZ3th3nJ/lsoQM8elPNWbhnrsjkYOFp23GUUs3M7qOnmPVGNvE92vCn0QNsx2mUTxd6cKA/KYnxVFRWMy01nQqdpyulapVVVJG8JJ0Af2FRYgKB/s2/Lpt/QhfrHRHKU+OHkL6vkGfXbLcdRynVTDz+zha2HDrJ8xNj6dampe04DvH5Qge4KbYrt43owcuf7+LjLUdsx1FKWfZ25gGWrt/H7y7vzVUDOtmO4zAt9FoP3TCIwV3DuOf1LPJOlNqOo5SyJDe/hPvfzObCqLbce11/23HOiRZ6reBAfxYnJVBdbUhOzaC8UufpSvma0+U1c/PgQH8WTvGMuXldnpXWxXq2b8UzE4aQtb+Qp97fZjuOUsrNHl21iZz8YuZPiqNzeLDtOOdMC72e0TFd+NXPovjbV7v5YNNh23GUUm7yxoY8VqTlkXxFHy7vF2E7TpNooTfg/usHEBsZzh9XZrHvmM7TlfJ2O44U89Bbm7ioVzvuuqav7ThNpoXegBYB/ixKTECA5NR0zlRW2Y6klHKR0vJKpi5Jp1ULfxZOiSfAw+bmdXluchfr3i6EZ2+NJftAEU++t9V2HKWUCxhjeOitTeQWlPDi5Hg6hnne3LwuhwpdREaJyHYRyRWRWQ3c31NE1orIRhH5VEQinR/V/X4+uDO3X9KLf36zl/c2HrIdRynlZK+n5fFm+gFmXNWXkX062I5z3hotdBHxB1KA0cAgYIqIDKq32HPAa8aYIcBsYK6zg9ryp1EDiOvehj+9sZHdR0/ZjqOUcpKth07y8NubGNmnPTOu9ty5eV2OPEMfDuQaY3YZY8qBZcDYessMAtbWXl7XwP0eKyjAj0WJ8fj7CclL0imr0Hm6Up6u5EwlyUvSCWsZyAuTan6/vYEjhd4N2F/nel7tbXVlAeNrL98CtBaR9ucfr3mIbBvC8xNj2XLoJLPf3WI7jlLqPBhjeODNbPYcO8WCyfFEtG5hO5LTOFLoDf3pMvWu3wtcLiIZwOXAAaDyRw8kcoeIpIlIWkGBZ53T8+qBnfjdZb1J/W4fb2cesB1HKdVEqev3sSrrIDOv6cfFF3jN807AsULPA7rXuR4JHKy7gDHmoDFmnDEmHniw9rai+g9kjHnZGDPMGDMsIsLzdty/9+f9GdqzLQ+8mc3OghLbcZRS52jTgSIef2cLl/btQPKVfWzHcTpHCv17oK+I9BKRIGAysKruAiLSQUR+eKz7gb85N2bzEOhfM08PCvAjeUk6p8t1nq6Upyguq2BaajptQwJ5YVIcfl4yN6+r0UI3xlQC04A1wFZghTFms4jMFpExtYtdAWwXkRygE/CEi/Ja1yW8JfMnxbHtcDGPrdpsO45SygHGGGa9kc3+E6dZOCWB9qHeMzevK8CRhYwxq4HV9W57pM7llcBK50Zrvq7o35HkKy8gZd1OLurdjnEJXrHbvVJe61/f7uW97EPcN6o/w3u1sx3HZfSdok0085p+XNSrHQ/+exM7jhTbjqOUOovsvCLmvLuVK/tH8PvLLrAdx6W00JsowN+PBVPiCQnyZ+qSdErLf7RTj1LKsqLTFUxN3UD70CDmTfTOuXldWujnoVNYMC9Ojie3oISH39J5ulLNiTGG+1ZmcaiwjEWJ8bRrFWQ7kstpoZ+nS/p2YMZVfXkjPY8Vafsb/wSllFv8/as9rNl8hD+NGsDQnt47N69LC90JZlzdl5F92vPI25vYfljn6UrZlrm/kLnvb+WagR35zaW9bMdxGy10J/D3E16YFE/r4ECmLtnAqTM6T1fKlsLScpKXpNOxdTDzbo1DxLvn5nVpoTtJROsWLJgcz+6jp3jw39kYU//oCEopVzPGcO/rG8kvLiMlKYHwkEDbkdxKC92JLr6gPTOv6cdbmQdZ9r3O05Vyt1e/2M3HW49w/+iBxHVvYzuO22mhO1nylX24tG8HHl21mS0HT9qOo5TP2LD3BE9/sI1Rgzvz65FRtuNYoYXuZH5+wguT4mgbEkhyajrFZRW2Iynl9U6cKmd6ajpd2gTz9IQhPjU3r0sL3QXah7Zg4ZQE9h0v5f43dZ6ulCtVVxvuXpHJ0ZJyFicOJbylb83N69JCd5Hhvdpxz3X9eHfjIf7n27224yjltV76fCfrthfw8I0DiYkMtx3HKi10F/r9ZRdwRf8I/vzuVrLzfnR4eKXUeVq/+zjzPszhhiFduG1ET9txrNNCdyE/P+H5iXG0Dw0iOTWdkzpPV8ppjpacYfrSdHq0C+GpcTE+OzevSwvdxdq1CmJRYjwHC09z3+sbdZ6ulBNUVxtmLs/kRGkFixJr3tSntNDdYmjPdtw3qj8fbD7MP77eYzuOUh4vZV0uX+w4ymM3DWZwV9+em9elhe4mv720N9cM7MiTq7eSub/QdhylPNbXO48y/+McxsZ1Zcrw7o1/gg/RQncTEeG5W2Pp2DqY5CXpFJXqPF2pc1VQfIY7l2US1aEVT96ic/P6tNDdqE1IzTw9v7iMe1dm6TxdqXNQVW24c1kGxWUVLE5KoFULh86g6VO00N0svkdbZo0eyEdbjvDqF7ttx1HKYyxYu4Ovdx5j9phoBnQOsx2nWdJCt+C/Rkbx88GdePqDbWzYe8J2HKWavS93HGXBJzsYl9CNW4fpSdnPRgvdAhHhmQmxdGkTzPTUdE6cKrcdSalmK/9kGXctz6BPRChzbo7WuflP0EK3JLxlICmJCRwtKefuFZlUV+s8Xan6Kquqmb40g1NnqliclEBIkM7Nf4oWukVDItvw4A0DWbe9gL9+vst2HKWanRc+3sF3u48z5+Zo+nZqbTtOs6eFbtkvLu7JDTFdeO7D7Xy/57jtOEo1G5/lFJDyaS4Th0UyfqjOzR2hhW6ZiDB3fAyRbVsyLTWdYyVnbEdSyrpDRaeZuTyTfh1b8/iYaNtxPIYWejMQFlwzTz9RWsHMFVk6T1c+rbKqmhlLMyirqCIlKYGWQf62I3kMLfRmIrpbOI/cOIjPcwpY/Gmu7ThKWfPchzl8v+cEc8fF0KdjqO04HkULvRlJuqgHY2K78vxHOXyz85jtOEq53SfbjvDSZzuZMrwHY+O62Y7jcbTQmxER4clxMUS1b8WMZRkUFOs8XfmOA4WnuXtFFoO6hPHoTYNsx/FIWujNTGiLAFKSEjh5uoK7lmdQpfN05QPKK6uZlppOZZVhcVICwYE6N28KLfRmaGCXMGaPHcxXucdY+MkO23GUcrlnPthGxr5Cnh4/hKgOrWzH8VgOFbqIjBKR7SKSKyKzGri/h4isE5EMEdkoItc7P6pvmTisO+Piu/Hi2h18lXvUdhylXObDzYd59cvdNe/JGNLFdhyP1mihi4g/kAKMBgYBU0Sk/oDrIWCFMSYemAwsdnZQXyMizLklmgsiQrlzWQb5J8tsR1LK6fYfL+Xe17OI6RbOgzcMtB3H4znyDH04kGuM2WWMKQeWAWPrLWOAH45nGQ4cdF5E3xUSFMDipAROnalixrIMKquqbUdSyml+mJsbICUxgRYBOjc/X44Uejdgf53rebW31fUYcJuI5AGrgekNPZCI3CEiaSKSVlBQ0IS4vqdfp9b8+eZovt11nBfX6jxdeY8nV28lK6+IZyfE0qN9iO04XsGRQm/oWJX1d72YAvzDGBMJXA/8S0R+9NjGmJeNMcOMMcMiIiLOPa2PmjA0kluHRrJoXS6f5egfQuX53s8+xD++3sOvR0YxKrqz7Thew5FCzwPqnok1kh+PVG4HVgAYY74BgoEOzgioasweG02/jq2ZuTyTw0U6T1eea++xU9y3ciOx3dtw/2idmzuTI4X+PdBXRHqJSBA1L3quqrfMPuBqABEZSE2h61NJJ2oZ5E9KUgJlFVVMX5qu83Tlkcoqqpi6JB0RWDQlnqAA3XPamRr9ahpjKoFpwBpgKzV7s2wWkdkiMqZ2sXuA34pIFrAU+JXRMyA7XZ+OoTx5Swzf7znBcx/m2I6j1Dmb894WNh88ybyJcXRvp3NzZ3Po9B/GmNXUvNhZ97ZH6lzeAox0bjTVkJvju/Hd7mO89NlOhvdqy1UDOtmOpJRD3sk6yP98u4/fXtqLawfpz60r6P87HujRmwYzsEsYd6/I4kDhadtxlGrUroISZr2xkYQebbhv1ADbcbyWFroHCg70JyUxnorKaqanplOh83TVjP0wNw8M8GNRYgKB/lo7rqJfWQ/VOyKUp8YPIX1fIc98sM12HKXO6vF3NrPtcDHzJ8bRtU1L23G8mha6B7sptiu3jejBK1/s5qMtR2zHUepH3so4wNL1+/n95Rdw5YCOtuN4PS10D/fQDYOI7hbGPSsy2X+81HYcpf4jN7+EB/6dzYVRbbn3un624/gELXQPVzNPT8AYmLY0g/JKnacr+06XV5G8JJ3gQH8WTkkgQOfmbqFfZS/Qs30rnpkwhKz9hcx9f6vtOErxyNubyMkvZv6kODqHB9uO4zO00L3E6Jgu/OpnUfz9qz18sOmQ7TjKh63ckMfrG/KYdmUfLu+nx2xyJy10L/LA9QOJjQznjys3su+YztOV++UcKeaht7IZ0bsdd12jc3N300L3IkG1+/kKkJyazpnKKtuRlA85daaSqUvSCW0RyILJ8fj7NXSgVuVKWuhepnu7EJ67NZbsA0U88Z7O05V7GGN4+K1N7Cwo4cXJcXQM07m5DVroXui6wZ35zSW9eO2bvby7UU8epVxvRdp+3sw4wJ1X92VkHz1yti1a6F7qT6MHEN+jDbPeyGb30VO24ygvtvXQSR55ezMj+7Rn+lV9bcfxaVroXirQv2aeHuAvJC9Jp6xC5+nK+UrOVJK8JJ2wloG8MEnn5rZpoXuxbm1a8vzEWLYcOsnsd7fYjqO8jDGGB97MZs+xUyycEk9E6xa2I/k8LXQvd9WATvzu8t6kfrePtzMP2I6jvEjq+n2syjrI3df2Y0Tv9rbjKLTQfcK91/Xnwqi23P9mNrn5JbbjKC+w6UARj7+zhcv6RTD1ij6246haWug+INDfj4VTEggO9Cd5STqny3WerpruZFkFyanptAsJYv7EWPx0bt5saKH7iM7hwcyfFEdOfjGPrtpkO47yUMYYZr2xkbwTp1mYGE/7UJ2bNyda6D7k8n4RJF/RhxVpeazckGc7jvJAr32zl9XZh2vHeO1sx1H1aKH7mLuu6ctFvdrx8Fub2HGk2HYc5UE25hUy570tXNk/gt9d1tt2HNUALXQfE+Dvx8Ip8bRq4c/UJemUllfajqQ8QNHpmrl5RGgLnp8Yp3PzZkoL3Qd1DAvmxcnx5BaU8NBbmzDG2I6kmjFjDPetzOJQYRkLExNo2yrIdiR1FlroPmpknw7MuKovb6Yf4PU0naers/vbV3tYs/kIs0YPYGjPtrbjqJ+ghe7DZlzdl5F92vPw25vYdvik7TiqGcrYd4K5q7dy7aBO3H5JL9txVCO00H2Yv5/wwqR4wloGMnVJOiVndJ6u/ldhaTnTUjPoHB7McxNiEdG5eXOnhe7jIlq3YMHkePYcPcWD/87WeboCaubm976eRX5xGSmJCYSHBNqOpBygha64+IL23H1tP97OPMjS9fttx1HNwCtf7OLjrfk8eP1AYru3sR1HOUgLXQEw9Yo+XNYvgsfe2czmg0W24yiLNuw9zjMfbOf6mM788mdRtuOoc6CFrgDw8xPmT4ylXUgQyUvSKS6rsB1JWXD8VM3cvGubljw1fojOzT2MFrr6j/ahLViYGM/+E6eZ9YbO031NdbXh7hWZHCspZ3FSAmHBOjf3NA4VuoiMEpHtIpIrIrMauH++iGTWfuSISKHzoyp3uDCqHfde15/3sg/xr2/32o6j3Oilz3fy6fYCHr5pENHdwm3HUU0Q0NgCIuIPpADXAnnA9yKyyhjzn1PgGGNm1ll+OhDvgqzKTX53WW/W7z7GnHe3Et+9LTGR+svt7dbvPs68D3O4cUgXbruoh+04qokceYY+HMg1xuwyxpQDy4CxP7H8FGCpM8IpO/z8hOcnxtEhNIipqRsoOq3zdG92tOQM05em06NdCHPHxejc3IM5UujdgLr7suXV3vYjItIT6AV8cpb77xCRNBFJKygoONesyo3atgpiYWIChwrLuG9lls7TvVRVtWHm8kwKSytISUygtc7NPZojhd7Qn+uz/XZPBlYaYxo8JY4x5mVjzDBjzLCIiAhHMypLhvZsy59GDWDN5iP8/as9tuMoF0hZl8sXO47y2JjBDOoaZjuOOk+OFHoe0L3O9Ujg4FmWnYyOW7zKby7txTUDO/Hk6q1k7DthO45yoq93HuWFj3O4Oa4rky/s3vgnqGbPkUL/HugrIr1EJIia0l5VfyER6Q+0Bb5xbkRlk4gw79ZYOoUFMy01g8LSctuRlBPkF5cxY2kmvTq04olbdG7uLRotdGNMJTANWANsBVYYYzaLyGwRGVNn0SnAMqPDVq8THhJISlIC+cVl3Pu6ztM9XVW14c6lmZScqWBx0lBatWh0ZzflIRz6ThpjVgOr6932SL3rjzkvlmpu4rq34f7RA5n97hZe+WIXd1x2ge1IqoleXLuDb3Yd45kJQ+jfubXtOMqJ9J2iymG/HhnFqMGdefqD7WzYe9x2HNUEX+woYOEnOxifEMnEYTo39zZa6MphIsLTE4bQtU3NPP34KZ2ne5IjJ8u4a1kmfSJC+fPNg23HUS6gha7OSXjLQBYnDuVYSTl3r8ikulrn6Z6gsqqa6UszKC2vYnFSAiFBOjf3Rlro6pzFRIbz0I0D+XR7AS99vtN2HOWA+R/nsH73cZ64JZq+nXRu7q200FWT/L8RPbkhpgvzPqwpCtV8fbo9n5R1O5k0rDvjEiJtx1EupIWumkREeGp8DN3btmT60nSOlpyxHUk14FDRaWYuz2RA59Y8Plbn5t5OC101Wevgmv3TT5RWMHO5ztObm4qqaqanZlBeWc3ipASCA/1tR1IupoWuzsvgruE8dtNgvthxlJR1ubbjqDqe+3A7aXtPMHf8EHpHhNqOo9xAC12dtynDuzM2rivzP87h651HbcdRwNqtR/jrZ7tIuqgHY2K72o6j3EQLXZ03EeHJW2KI6tCKO5dlUlCs83Sb8k6UcveKLAZ3DePhGwfZjqPcSAtdOUWrFgEsTkqguKyCO5dlUKXzdCvKK6uZllrz9U9J1Lm5r9FCV04zoHMYs8dE8/XOYyxYu8N2HJ/09AfbyNxfyDMThhDVoZXtOMrNtNCVU906LJJxCd1Y8MkOvtyh83R3WrP5MP/95W5+eXFPro/pYjuOskALXTmViDDn5mj6RIRy1/IM8k+W2Y7kE/YfL+Xe17OI6RbOAzcMtB1HWaKFrpwuJKhmnn7qTBXTl2ZQWVVtO5JXO1NZRXJqOgCLkxJoEaBzc1+lha5com+n1sy5OZrvdh/nhY91nu5Kc1dvY2NeEc9OiKV7uxDbcZRFWujKZcYPjWTisEhSPs3ls5wC23G80ursQ/zj6z3818hejIrubDuOskwLXbnU42Oi6dexNTOXZ3Ko6LTtOF5l77FT/GnlRmK7t2HW6AG246hmQAtduVTLIH9SkhIoq6hihs7TnaasooqpS9Lx8xNSEuMJCtBfZaWFrtygT8dQ5o6L4fs9J3juwxzbcbzCnPe2sPngSebdGktkW52bqxpa6MotxsZ1Y8rwHrz02U4+2XbEdhyP9k7WQf7n233ccVlvrhnUyXYc1YxooSu3efSmQQzqEsbdK7I4UKjz9KbYVVDCrDc2MrRnW/748/6246hmRgtduU1wYM08vbLKMC01nfJKnaefix/m5kEBfiycEk+gv/76qv9LfyKUW/Xq0IqnxseQsa+QZz7YZjuOR3ls1Wa2HS7m+UlxdG3T0nYc1QxpoSu3u3FIV35xcU9e/XI3H24+bDuOR/h3Rh7Lvt/PH664gCv7d7QdRzVTWujKigdvGEhMt3DufT2L/cdLbcdp1nLzi3ngzU0Mj2rHPdf2sx1HNWNa6MqKFgH+pCQmYEDn6T+htLySqUvSCQnyZ8GUeAJ0bq5+gv50KGt6tA/h2QmxZOUV8eTqrbbjNEuPvL2ZHfklzJ8UR+fwYNtxVDOnha6sGhXdmV+PjOIfX+/h/exDtuM0K6+n7WflhjymXdmHy/pF2I6jPIAWurLu/tEDie3ehvtWbmTvsVO24zQL2w8X8/DbmxjRux13XaNzc+UYLXRlXVCAHymJ8YhAcmo6ZRVVtiNZdepMJVOXbCC0RSALJsfj7ye2IykPoYWumoXItiHMmxjHpgMneeI9352nG2N46K1N7Dp6ihcnx9ExTOfmynEOFbqIjBKR7SKSKyKzzrLMRBHZIiKbRSTVuTGVL7h2UCfuuKw3//p2L+9kHbQdx4rl3+/n3xkHuOvqfozs08F2HOVhGi10EfEHUoDRwCBgiogMqrdMX+B+YKQxZjBwlwuyKh/wx5/3Z2jPttz/Zja7j/rWPH3roZM8umozl/TpwLSr+tiOozyQI8/QhwO5xphdxphyYBkwtt4yvwVSjDEnAIwx+c6NqXxFoP8PxykRpi7xnXl6yZlKkpekE94ykBcmx+ncXDWJI4XeDdhf53pe7W119QP6ichXIvKtiIxq6IFE5A4RSRORtIICPSWZaljXNi15flIcWw+d5PF3ttiO43LGGO5/M5s9x06xYEo8HUJb2I6kPJQjhd7QUwVT73oA0Be4ApgCvCoibX70Sca8bIwZZowZFhGh+9Wqs7uyf0f+cMUFLF2/j7czD9iO41JLvtvHO1kHuee6/ozo3d52HOXBHCn0PKB7neuRQP1XrPKAt40xFcaY3cB2agpeqSa759p+DI9qx/1vZpObX2I7jktsOlDE7He3cHm/CP5w+QW24ygP50ihfw/0FZFeIhIETAZW1VvmLeBKABHpQM0IZpczgyrfE+Dvx4Ip8WSAE0MAAAqnSURBVLQM9Cd5STqny71rnn6yrILk1HTahQTx/MRY/HRurs5To4VujKkEpgFrgK3ACmPMZhGZLSJjahdbAxwTkS3AOuCPxphjrgqtfEfn8GDmT4ojJ7+YR1dtsh3HaYwxzHpjI3knTrMoMZ72OjdXThDgyELGmNXA6nq3PVLnsgHurv1Qyqku6xfBtCv7sPCTXIb3as+EoZG2I523177Zy+rsw8waPYBhUe1sx1FeQt8pqjzCXdf0Y0Tvdjz0VjY5R4ptxzkvWfsLmfPeFq4e0JE7Lu1tO47yIlroyiP4+wkLJscT2iKQqUvSOXWm0nakJikqrZmbd2wdzDydmysn00JXHqNjWDAvTo5jZ0EJD7+1iZpJn+cwxnDvyiwOF5WxMDGeNiFBtiMpL6OFrjzKyD4duPPqvryZcYAVafsb/4Rm5L+/3M1HW44wa/QAEnq0tR1HeSEtdOVxpl/Vl0v6dOCRtzez9dBJ23Eckr7vBE+9v43rBnXi9kt62Y6jvJQWuvI4/n7C/ElxhLcMJHlJOiXNfJ5eWFrO9NQMOocH8+yEWER0bq5cQwtdeaSI1i1YMCWePcdO8cCb2c12nl5dbbhnRRb5xWWkJCYQHhJoO5LyYlroymON6N2eu6/tx6qsg6Su32c7ToNe+WIXa7fl8+D1NafZU8qVtNCVR5t6Rc0JlB9/ZwubDhTZjvN/pO05zjNrtnN9TGd++bMo23GUD9BCVx7Nz0+YPzGWdiFBJKemc7KswnYkAI6fKmdaagaRbVvy1PghOjdXbqGFrjxe+9AWLEyMJ+/EaWa9sdH6PL262jBzeSbHS8tJSUwgLFjn5so9tNCVV7gwqh1//Hl/Vmcf5rVv9lrN8pfPdvJZTgGP3DiI6G7hVrMo36KFrrzGHZf25qoBHZnz3hY25hVayfDdrmPM+3A7N8V2JemiHlYyKN+lha68hp+fMO/WWCJCW5Ccmk7RaffO04+WnGH60gx6tm/F3HExOjdXbqeFrrxK21ZBLEpK4FBhGfetzHLbPL2qdm5edLqCxUkJhLZw6MjUSjmVFrryOgk92jJr9ADWbD7C377a45Z1pqzL5YsdR3l8zGAGdglzyzqVqk8LXXml2y/pxbWDOjF39VYy9p1w6bq+3nmUFz7O4Zb4bky6sHvjn6CUi2ihK68kIjw3IZbO4cFMS82gsLTcJevJLy5jxtJMenVoxZybo3VurqzSQldeKzwkkJTEBPKLy7hnRRbV1c6dp1dVG+5cmknJmQoWJw2llc7NlWVa6MqrxXZvwwPXD2Tttnxe+WKXUx/7xY9z+GbXMf48Npr+nVs79bGVagotdOX1fvWzKEZHd+aZNdtJ23PcKY/5eU4BC9flMmFoJLcO07m5ah600JXXExGenjCEbm1aMi01g+Onzm+efuRkGTOXZ9K3Yyh/HhvtpJRKnT8tdOUTwoIDWZyUwPFT5cxcntnkeXplVTXTUzMoLa9icVICLYP8nZxUqabTQlc+I7pbOA/fOJDPcgr4y2c7m/QYz3+Uw/o9x3lyXDR9OurcXDUvWujKp9w2oic3DunCvA+3s373uc3T123PZ/GnO5l8YXduiY90UUKlmk4LXfkUEWHuuBh6tm/F9KXpHC0549DnHSw8zd3LMxnQuTWPjRns4pRKNY0WuvI5rYMDWZQYz4nSCofm6RVV1UxfmkF5ZTWLkxIIDtS5uWqetNCVTxrcNZzHbhrMFzuOkrIu9yeXfW7NdjbsPcHc8UPoHRHqpoRKnTstdOWzpgzvzs1xXZn/cQ5f7zza4DJrtx7hr5/v4rYRPRgT29XNCZU6N/peZeWzRIQnbokh+0ARv/1nGl3btPzRMnknTjO4axgP3TDIQkKlzo0WuvJprVoE8PIvhrHok1zOVFb96P4hkW2465q+OjdXHsGhQheRUcCLgD/wqjHmqXr3/wp4FjhQe9MiY8yrTsyplMtcEBHK/ElxtmModd4aLXQR8QdSgGuBPOB7EVlljNlSb9HlxphpLsiolFLKAY68KDocyDXG7DLGlAPLgLGujaWUUupcOVLo3YD9da7n1d5W33gR2SgiK0WkwcPPicgdIpImImkFBQVNiKuUUupsHCn0hk7BUv+dGO8AUcaYIcDHwD8beiBjzMvGmGHGmGERERHnllQppdRPcqTQ84C6z7gjgYN1FzDGHDPG/PAe6leAoc6Jp5RSylGOFPr3QF8R6SUiQcBkYFXdBUSkS52rY4CtzouolFLKEY3u5WKMqRSRacAaanZb/JsxZrOIzAbSjDGrgBkiMgaoBI4Dv3JhZqWUUg0QY5x74lxHDRs2zKSlpVlZt1JKeSoR2WCMGdbgfbYKXUQKgL1N/PQOQMMH3/Beus2+QbfZN5zPNvc0xjS4V4m1Qj8fIpJ2tr9Q3kq32TfoNvsGV22zHm1RKaW8hBa6Ukp5CU8t9JdtB7BAt9k36Db7Bpdss0fO0JVSSv2Ypz5DV0opVY8WulJKeYlmXegiMkpEtotIrojMauD+FiKyvPb+70Qkyv0pncuBbb5bRLbUHtlyrYj0tJHTmRrb5jrLTRARIyIev4ubI9ssIhNrv9ebRSTV3RmdzYGf7R4isk5EMmp/vq+3kdNZRORvIpIvIpvOcr+IyILar8dGEUk475UaY5rlBzWHGdgJ9AaCgCxgUL1lpgIv1V6eTM1JNqxnd/E2XwmE1F7+gy9sc+1yrYHPgW+BYbZzu+H73BfIANrWXu9oO7cbtvll4A+1lwcBe2znPs9tvgxIADad5f7rgfepOaLtCOC7811nc36G7siJNcbyv4fqXQlcLSINHe7XUzS6zcaYdcaY0tqr31Jz9EtP5ugJVP4MPAOUuTOciziyzb8FUowxJwCMMfluzuhsjmyzAcJqL4dT76iunsYY8zk1x7Y6m7HAa6bGt0Cbegc6PGfNudAdObHGf5YxxlQCRUB7t6RzDUdPJvKD26n5C+/JGt1mEYkHuhtj3nVnMBdy5PvcD+gnIl+JyLe15/X1ZI5s82PAbSKSB6wGprsnmjXn+vveKIdOEm2JIyfWcGQZT+Lw9ojIbcAw4HKXJnK9n9xmEfED5uNdR/B05PscQM3Y5Qpq/gv7QkSijTGFLs7mKo5s8xTgH8aYeSJyMfCv2m2udn08K5zeX835GXqjJ9aou4yIBFDzb9pP/YvT3DmyzYjINcCDwBjzvycW8VSNbXNrIBr4VET2UDNrXOXhL4w6+rP9tjGmwhizG9hOTcF7Kke2+XZgBYAx5hsgmJqDWHkrh37fz0VzLvRGT6xRe/2XtZcnAJ+Y2lcbPJQjJxOJB/5KTZl7+lwVGtlmY0yRMaaDMSbKGBNFzesGY4wxnnzsZUd+tt+i5gVwRKQDNSOYXW5N6VyObPM+4GoAERlITaF788mHVwG/qN3bZQRQZIw5dF6PaPuV4EZeJb4eyKHm1fEHa2+bTc0vNNR8w18HcoH1QG/bmd2wzR8DR4DM2o9VtjO7epvrLfspHr6Xi4PfZwGeB7YA2cBk25ndsM2DgK+o2QMmE7jOdubz3N6lwCGggppn47cDvwd+X+d7nFL79ch2xs+1vvVfKaW8RHMeuSillDoHWuhKKeUltNCVUspLaKErpZSX0EJXSikvoYWulFJeQgtdKaW8xP8HhCwSG0HIkWcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ps, cav_test[2, 2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cav_v[2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(cav_test[2, 2, :] == np.max(cav_test[2, 2, :]))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Cav of V -- For 2 Time steps (state_dim = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cav_v(timestep, game_dict, states, p, returnstate=0):\n",
    "    \n",
    "    def get_game_dict(timestep, game_dict, states, p, valuefun = get_cav_v):\n",
    "        return valuefun(timestep, game_dict, states, p, returnstate=1)\n",
    "    \n",
    "    if timestep == 1:\n",
    "        cav_v, _, = get_inter_value(1, game_dict, states)\n",
    "        ps = np.linspace(0, 1, 50)\n",
    "        cav_test = np.zeros((5, 5, len(ps)))\n",
    "        ps = np.linspace(0, 1, 50)\n",
    "        cav_test = np.zeros((5, 5, len(ps)))\n",
    "        for i in range(len(ps)):\n",
    "            average_game = get_av_val(val_R_T, val_L_T, p=ps[i])\n",
    "            average_dict = dict(zip(s_pairs.flatten(), average_game.flatten()))\n",
    "            temp, _ = get_inter_value(1, average_dict, s_pairs)\n",
    "            cav_test[:, :, i] = temp\n",
    "\n",
    "        for row in range(5):\n",
    "            for col in range(timestep, num_states-timestep):\n",
    "                vals = cav_test[row, col, :]\n",
    "                if len(np.where(vals == np.max(vals))[0]) > 1:\n",
    "                    p_min = ps[np.where(vals == np.max(vals))[0][0]]\n",
    "                    if p > p_min:\n",
    "                        cav_v[row, col] = np.max(vals)\n",
    "#         print(p)\n",
    "#         if p > 0.37:\n",
    "#             printMatrix(cav_v)\n",
    "#             input()\n",
    "    \n",
    "    if timestep > 1 and returnstate==0:\n",
    "        ps = np.linspace(0, 1, 50)\n",
    "        cav_v, _, = get_inter_value(timestep, game_dict, states)\n",
    "        for i in range(1, timestep):\n",
    "            cavs = np.zeros((num_states, num_states, len(ps)))\n",
    "            for j in range(len(ps)):\n",
    "                av_game = get_av_val(val_R_T, val_L_T, p=ps[j])\n",
    "                av_dict = dict(zip(states.flatten(), av_game.flatten()))\n",
    "                cavs[:, :, j] = get_game_dict(i, av_dict, states, p=ps[j])\n",
    "            \n",
    "            for row in range(num_states):\n",
    "                for col in range(i, num_states-i):\n",
    "                    vals = cavs[row, col, :]\n",
    "#                     if row == 0 and col == 1:\n",
    "#                         print(np.where(vals == np.max(vals)))\n",
    "                    if len(np.where(vals == np.max(vals))[0]) > 1:\n",
    "                        p_min = ps[np.where(vals == np.max(vals))[0][0]]\n",
    "                        p_max = ps[np.where(vals == np.max(vals))[0][-1]]\n",
    "#                         print(p_max)\n",
    "                        if p > p_min and p < p_max:\n",
    "                            cav_v[row, col] = np.max(vals)\n",
    "    return cav_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0     1     2     3     4 \n",
      "     ------------------------------\n",
      "  0 |  nan  0.49   0.1   0.2   nan \n",
      "  1 |  nan   0.9   0.1   0.2   nan \n",
      "  2 |  nan   1.8   1.0   0.2   nan \n",
      "  3 |  nan   1.8   0.9   0.1   nan \n",
      "  4 |  nan   1.8   0.9  0.49   nan \n"
     ]
    }
   ],
   "source": [
    "num_states = 5\n",
    "average_game = get_av_val(val_R_T, val_L_T, p=0.1)\n",
    "average_dict = dict(zip(s_pairs.flatten(), average_game.flatten()))\n",
    "printMatrix(get_cav_v(1, average_dict, s_pairs, p=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cav_v(1, average_dict, s_pairs, p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "import random\n",
    "from itertools import product\n",
    "\n",
    "def get_strategy(game_dict, states, p):\n",
    "    '''\n",
    "    @params: lambda_j >= 0\n",
    "             p_j \\in {p_1, 1-p_1}\n",
    "             \n",
    "    constraints: \\sum lambda_j = 1\n",
    "                 \\sum lambda_j*p_j = p\n",
    "    '''\n",
    "    # first get strategy at initial time-step\n",
    "    # initial state is always (2, 2)\n",
    "    \n",
    "    def optimization(p, V_curr, curr_x, game_dict):\n",
    "    \n",
    "        def constraint(var):\n",
    "            lam_1 = var[0]\n",
    "            lam_2 = 1 - lam_1\n",
    "            p_1 = var[1]\n",
    "            p_2 = var[2]\n",
    "\n",
    "            lam_j = np.array([[lam_1], [lam_2]])\n",
    "            p_j = np.array([[p_1], [p_2]])\n",
    "\n",
    "            return abs((np.matmul(lam_j.T, p_j) - p).item()) <= 5e-4\n",
    "\n",
    "        def objective(var):\n",
    "\n",
    "            # here, V_curr is the value at the current state\n",
    "            # V_next is the max min value at the previous state leading to current state\n",
    "            lam_1 = var[0]\n",
    "            lam_2 = 1 - lam_1\n",
    "            p_1 = var[1]\n",
    "            p_2 = var[2]\n",
    "\n",
    "            lam_j = np.array([[lam_1], [lam_2]])\n",
    "            v_next = np.zeros((2, 1))\n",
    "            if curr_x == [2, 2]:\n",
    "                v_next_0 = get_cav_v(1, game_dict, states, p_1)\n",
    "                v_next_1 = get_cav_v(1, game_dict, states, p_2)\n",
    "                \n",
    "                pay_0 = np.zeros((4, 2))\n",
    "                pay_1 = np.zeros((4, 2))\n",
    "                \n",
    "                pay_0[0, 0] = v_next_0[1, 1]\n",
    "                pay_0[0, 1] = v_next_0[1, 3]\n",
    "                pay_0[1, 0] = v_next_0[0, 1]\n",
    "                pay_0[1, 1] = v_next_0[0, 3]\n",
    "                pay_0[2, 0] = v_next_0[3, 1]\n",
    "                pay_0[2, 1] = v_next_0[3, 3]\n",
    "                pay_0[3, 0] = v_next_0[4, 1]\n",
    "                pay_0[3, 1] = v_next_0[4, 3]\n",
    "                \n",
    "                pay_1[0, 0] = v_next_1[1, 1]\n",
    "                pay_1[0, 1] = v_next_1[1, 3]\n",
    "                pay_1[1, 0] = v_next_1[0, 1]\n",
    "                pay_1[1, 1] = v_next_1[0, 3]\n",
    "                pay_1[2, 0] = v_next_1[3, 1]\n",
    "                pay_1[2, 1] = v_next_1[3, 3]\n",
    "                pay_1[3, 0] = v_next_1[4, 1]\n",
    "                pay_1[3, 1] = v_next_1[4, 3]\n",
    "                \n",
    "                # do min max on v_next\n",
    "                v_next[0] = np.max(np.min(pay_0, 1))\n",
    "                v_next[1] = np.max(np.min(pay_1, 1))\n",
    "                \n",
    "            else: # that is, some other state in the second time-step\n",
    "                \n",
    "                i = curr_x[0]\n",
    "                j = curr_x[1]\n",
    "                \n",
    "                v_next_0 = get_av_val(val_R_T, val_L_T, p_1)\n",
    "                v_next_1 = get_av_val(val_R_T, val_L_T, p_1)\n",
    "                \n",
    "                pay_0 = np.zeros((4, 2))\n",
    "                pay_1 = np.zeros((4, 2))\n",
    "                \n",
    "                if i - 1 < 0:\n",
    "                    new_L = i\n",
    "                    new_l = i\n",
    "                elif i - 2 < 0:\n",
    "                    new_L = i - 1\n",
    "                    new_l = i - 1\n",
    "                else:\n",
    "                    new_l = i - 1\n",
    "                    new_L = i - 2\n",
    "                    \n",
    "                if i + 1 > num_states - 1:\n",
    "                    new_R = i\n",
    "                    new_r = i\n",
    "                elif i + 2 > num_states - 1:\n",
    "                    new_r = i + 1 \n",
    "                    new_R = i + 1\n",
    "                else:\n",
    "                    new_r = i + 1\n",
    "                    new_R = i + 2\n",
    "\n",
    "                pay_0[0, 0] = v_next_0[new_l, j-1] # left left\n",
    "                pay_0[0, 1] = v_next_0[new_l, j+1] # left right\n",
    "                pay_0[1, 0] = v_next_0[new_L, j-1] # Left left\n",
    "                pay_0[1, 1] = v_next_0[new_L, j+1] # Left right\n",
    "                pay_0[2, 0] = v_next_0[new_r, j-1] # right left\n",
    "                pay_0[2, 1] = v_next_0[new_r, j+1] # right right\n",
    "                pay_0[3, 0] = v_next_0[new_R, j-1] # Right left\n",
    "                pay_0[3, 1] = v_next_0[new_R, j+1] # Right right\n",
    "                \n",
    "                pay_0[0, 0] = v_next_0[new_l, j-1] # left left\n",
    "                pay_0[0, 1] = v_next_0[new_l, j+1] # left right\n",
    "                pay_0[1, 0] = v_next_0[new_L, j-1] # Left left\n",
    "                pay_0[1, 1] = v_next_0[new_L, j+1] # Left right\n",
    "                pay_0[2, 0] = v_next_0[new_r, j-1] # right left\n",
    "                pay_0[2, 1] = v_next_0[new_r, j+1] # right right\n",
    "                pay_0[3, 0] = v_next_0[new_R, j-1] # Right left\n",
    "                pay_0[3, 1] = v_next_0[new_R, j+1] # Right right\n",
    "                \n",
    "                # do min max on v_next\n",
    "                v_next[0] = np.max(np.min(pay_0, 1))\n",
    "                v_next[1] = np.max(np.min(pay_1, 1))\n",
    "    \n",
    "            return (V_curr -  np.matmul(lam_j.T, v_next)).item()\n",
    "    \n",
    "        \n",
    "        cons = ({'type': 'eq', 'fun': constraint})\n",
    "        bnds = ((0, 1), (0, 1), (0, 1), (p, p))\n",
    "#         x0 = [0, 0, 0, p]\n",
    "        \n",
    "        # cannot use scipy optimization\n",
    "#         res = minimize(objective, x0, bounds = bnds, constraints = cons, options={'disp': True})\n",
    "#         print(objective(x0))\n",
    "\n",
    "        lam = np.linspace(0, 1, 50)\n",
    "#         p_1 = np.arange(0, 1, 0.25)\n",
    "#         p_2 = np.arange(0, 1, 0.25)\n",
    "        \n",
    "        grid = product(lam, repeat=3)\n",
    "        reduced = filter(constraint, grid)\n",
    "        res = min(reduced, key=objective)\n",
    "        \n",
    "        \n",
    "        return res\n",
    "       \n",
    "    \n",
    "    p_t = p\n",
    "    a_map = {'0': 'l', '1': 'L', '2': 'r', '3': 'R'}\n",
    "    # first get strategy for initial state (2, 2)\n",
    "    start_x = [2, 2]\n",
    "    V_curr = get_cav_v(2, game_dict, states, p)[2, 2]\n",
    "    \n",
    "    lam_j, p_1, p_2 = optimization(p, V_curr, start_x, game_dict)\n",
    "    print(lam_j, p_1, p_2)\n",
    "    input()\n",
    "    \n",
    "    \n",
    "    # action for lam_1 \n",
    "    game_dict_1 = get_av_val(val_R_T, val_L_T, p_1)\n",
    "    game_dict_1 = dict(zip(s_pairs.flatten(), game_dict_1.flatten()))\n",
    "    game_dict_2 = get_av_val(val_R_T, val_L_T, p_2)\n",
    "    game_dict_2 = dict(zip(s_pairs.flatten(), game_dict_2.flatten()))\n",
    "\n",
    "    v_next_0 = get_cav_v(1, game_dict_1, states, p_1)\n",
    "    v_next_1 = get_cav_v(1, game_dict_2, states, p_2)\n",
    "    \n",
    "    pay_0 = np.zeros((4, 2))\n",
    "    pay_1 = np.zeros((4, 2))\n",
    "\n",
    "    pay_0[0, 0] = v_next_0[1, 1]\n",
    "    pay_0[0, 1] = v_next_0[1, 3]\n",
    "    pay_0[1, 0] = v_next_0[0, 1]\n",
    "    pay_0[1, 1] = v_next_0[0, 3]\n",
    "    pay_0[2, 0] = v_next_0[3, 1]\n",
    "    pay_0[2, 1] = v_next_0[3, 3]\n",
    "    pay_0[3, 0] = v_next_0[4, 1]\n",
    "    pay_0[3, 1] = v_next_0[4, 3]\n",
    "    \n",
    "    v_0 = np.max(np.min(pay_0, 1))\n",
    "    a_0 = None\n",
    "    a_0_idx = np.where(np.min(pay_0, 1) == v_0)[0] # check for same values\n",
    "    if len(a_0_idx) == 1:\n",
    "        a_0 = a_map[str(a_0_idx[0])]\n",
    "    elif len(a_0_idx) == 4:\n",
    "        a_0 = 'A'\n",
    "    else:\n",
    "        ac = ''\n",
    "        for a in a_0_idx:\n",
    "            ac += a_map[str(a)]\n",
    "        a_0 = ac\n",
    "\n",
    "    pay_1[0, 0] = v_next_1[1, 1]\n",
    "    pay_1[0, 1] = v_next_1[1, 3]\n",
    "    pay_1[1, 0] = v_next_1[0, 1]\n",
    "    pay_1[1, 1] = v_next_1[0, 3]\n",
    "    pay_1[2, 0] = v_next_1[3, 1]\n",
    "    pay_1[2, 1] = v_next_1[3, 3]\n",
    "    pay_1[3, 0] = v_next_1[4, 1]\n",
    "    pay_1[3, 1] = v_next_1[4, 3]\n",
    "    \n",
    "    v_1 = np.max(np.min(pay_1, 1))\n",
    "    a_1 = None\n",
    "    a_1_idx = np.where(np.min(pay_1, 1) == v_1)[0] # check for same values\n",
    "    if len(a_1_idx) == 1:\n",
    "        a_1 = a_map[str(a_1_idx[0])]\n",
    "    elif len(a_1_idx) == 4:\n",
    "        a_1 = 'A'\n",
    "    else:\n",
    "        ac = ''\n",
    "        for a in a_1_idx:\n",
    "            ac += a_map[str(a)]\n",
    "        a_1 = ac\n",
    "        \n",
    "    # calculate probability of each action\n",
    "    if p1_type == 0:\n",
    "        p_i = 1 - p\n",
    "        p_1j = 1 - p_1\n",
    "        p_2j = 1 - p_2\n",
    "    else:\n",
    "        p_i = p \n",
    "        p_1j = p_1\n",
    "        p_2j = p_2\n",
    "    \n",
    "    a0_p = (lam_j * p_1j)/p_i\n",
    "    a1_p = ((1-lam_j) * p_2j)/p_i\n",
    "    \n",
    "    print('At initial time, P1 has the following options: \\n')\n",
    "    print(f'P1 takes action {a_0} with probability {a0_p} and moves belief to {p_1}\\n')\n",
    "    print(f'P1 takes action {a_1} with probability {a1_p} and moves belief to {p_2}')\n",
    "    \n",
    "    # Now get strategy for second stage:\n",
    "    # assume we know action at t0 is A (anything)\n",
    "    \n",
    "#     a_0 = np.random.choice(list(a_map.keys()), size=1, p=[0.25, 0.25, 0.25, 0.25])\n",
    "#     print(a_map[a_0.item()])\n",
    "    p_t = p_2\n",
    "    \n",
    "    \n",
    "    return (a_0, lam_j, p_1), (a_1, 1-lam_j, p_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = 5\n",
    "# curr_x = [2, 2]\n",
    "p = 0.15\n",
    "p1_type = 1 # 0 for right, 1 for left\n",
    "average_game = get_av_val(val_R_T, val_L_T, p=p)\n",
    "average_dict = dict(zip(s_pairs.flatten(), average_game.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7346938775510203 0.02040816326530612 0.5102040816326531\n",
      "\n",
      "At initial time, P1 has the following options: \n",
      "\n",
      "P1 takes action l with probability 0.09995835068721365 and moves belief to 0.02040816326530612\n",
      "\n",
      "P1 takes action r with probability 0.9024017770373459 and moves belief to 0.5102040816326531\n"
     ]
    }
   ],
   "source": [
    "l_1, l_2 = get_strategy(average_dict, s_pairs, p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
